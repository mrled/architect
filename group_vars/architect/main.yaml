---

##
#### Architect group-wide vars
## Prefix: architect_
## Purpose: vars used directly in the architect playbook, or shared by multiple roles
##

# Docker data volume device name/mount point on the EC2 instance
# Note that the EBS volume that results is _not_ deleted on termination
architect_docker_volume:
    device: xvdj
    mountpoint: /var/lib/docker

# Local path to save an SSH script
# Only used to have an easy way to connect for manual debugging
architect_ssh_script_path: "{{ all_workdir }}/ssh-architect.sh"

# Admin user for the architect instance
architect_admin_user: architect

# Generate SSH client key
# Generate a client key that we can use to connect to the architect instance
# We do this ahead of time so that its saved to the repo, encrypted in the vault
# ssh-keygen -q -f ./architect.pem -N '' -t ecdsa && cat ./architect.pem | base64
# (Note: public key can be generated from the private key, no need to save it here)
architect_ssh_client_key:
    priv_b64: "{{ vault_architect_ssh_client_ecdsa_key_b64 }}"
    priv_path: "{{ all_workdir }}/architect.pem"
    pub_path: "{{ all_workdir }}/architect.pem.pub"

##
#### cfn_dockerhost role vars
## Prefix: cfn_dockerhost_
##

# CloudFormation stack name
cfn_dockerhost_ci_stackname: ArchitectCi

cfn_dockerhost_docker_volume_device: "{{ architect_docker_volume.device }}"
cfn_dockerhost_workdir: "{{ all_workdir }}"
cfn_dockerhost_known_hosts_file: "{{ all_known_hosts_file }}"
cfn_docker_ssh_script_path: "{{ architect_ssh_script_path }}"
cfn_dockerhost_ssh_client_key: "{{ architect_ssh_client_key }}"
cfn_dockerhost_aws_cfg: "{{ all_aws_cfg }}"
cfn_dockerhost_deploy_bucket: "{{ all_deploy_bucket }}"
cfn_dockerhost_admin_user: "{{ architect_admin_user }}"

##
#### dockerhost role vars
## Prefix: dockerhost_
##

dockerhost_docker_volume: "{{ architect_docker_volume }}"

##
#### algoclient role vars
## Prefix: algoclient_
##

# The VPN host - either an IP address or a domain name
algoclient_vpn_host: newtroy.micahrl.com

# The parameterized contents of Algo's 'ipsec_USER.secrets' file:
algoclient_ipsec_secrets: "{{ algoclient_vpn_host }} : ECDSA architect.key"

# The contents of Algo's ipsec_USER.conf file
# We parameterize this where we can, and make a couple of changes, documented in the comments
algoclient_ipsec_conf: |+
    conn ikev2-{{ algoclient_vpn_host }}
        fragmentation=yes
        rekey=no
        keyexchange=ikev2
        compress=no
        dpddelay=35s

        ike=aes128gcm16-prfsha512-ecp256,aes128-sha2_512-prfsha512-ecp256,aes128-sha2_384-prfsha384-ecp256!
        esp=aes128gcm16-ecp256,aes128-sha2_512-prfsha512-ecp256!

        right={{ algoclient_vpn_host }}
        rightid={{ algoclient_vpn_host }}
        rightauth=pubkey

        # Change from Algo-generated version: allow any IP address
        # Upstream Algo only uses IP addresses and sets right=W.X.Y.Z,
        # but my fork can configure a domain name
        rightallowany=yes

        # Change from Algo-generated version: only use VPN for VPN hosts
        # aka "split-tunneling"
        # This means ONLY pass traffic destined for this network over the VPN
        rightsubnet=10.19.48.0/24

        # Change from Algo-generated version: restart dead peers
        dpdaction=restart

        # Change from Algo-generated version: keep trying to connect to the server forever
        keyingtries=%forever

        leftsourceip=%config
        leftauth=pubkey
        leftid=architect
        leftcert=architect.crt
        leftfirewall=yes
        left=%defaultroute

        # We don't use auto=route because it doesn't work with leftsourceip=%config
        # We use dbdaction=restart, keyingtries=%forever, and auto=start instead
        # See https://wiki.strongswan.org/issues/2162
        # TODO: I think this means we can get rid of our VPN keepalive pings?
        auto=start

# The CA cert from Algo
algoclient_cacert: |
    -----BEGIN CERTIFICATE-----
    MIIBwjCCAWegAwIBAgIJAIrq5lHj1GWaMAoGCCqGSM49BAMCMB4xHDAaBgNVBAMM
    E25ld3Ryb3kubWljYWhybC5jb20wHhcNMTgwNTA1MTk1OTE2WhcNMjgwNTAyMTk1
    OTE2WjAeMRwwGgYDVQQDDBNuZXd0cm95Lm1pY2FocmwuY29tMFkwEwYHKoZIzj0C
    AQYIKoZIzj0DAQcDQgAEajSK8iKvtQFheeIpsFv19jW1jqJBxzQ2zSkwuZQf0M1G
    F41K4q915Wg2lip5GMOR5949UEwphUQ7rGcj1ExEH6OBjTCBijAdBgNVHQ4EFgQU
    CGrXFKHGKHLrX2ZWF7AQsThIMaswTgYDVR0jBEcwRYAUCGrXFKHGKHLrX2ZWF7AQ
    sThIMauhIqQgMB4xHDAaBgNVBAMME25ld3Ryb3kubWljYWhybC5jb22CCQCK6uZR
    49RlmjAMBgNVHRMEBTADAQH/MAsGA1UdDwQEAwIBBjAKBggqhkjOPQQDAgNJADBG
    AiEAtioe8S83H2rohtjtGpuWkp9TrtdXONQfi4Wywg5ahCsCIQDCm9/WQV1j/0yH
    LOyD/wwFOIwDZew/9ZsacfMqMc8dsg==
    -----END CERTIFICATE-----

# Get the user's VPN cert and private key, generated from Algo
# openssl pkcs12 -in "architect.p12" -clcerts -nokeys -passin pass:$ALGO_GENERATED_PKCS12PASS 2>/dev/null
# openssl pkcs12 -in "architect.p12" -nocerts -passin pass:$ALGO_GENERATED_PKCS12PASS -nodes 2>/dev/null
algoclient_vpn_cert: "{{ vault_algo_vpn_cert }}"
algoclient_vpn_key: "{{ vault_algo_vpn_key }}"

# A host to ping periodically to keep the VPN tunnel up
# Can be anything that goes over the rightsubnet routes in ipsec.conf
algoclient_vpn_keepalive_host: "architect.internal.micahrl.com"

##
#### jenkins_swarm role vars
## Prefix: jenkins_swarm_
##

# The domain name to use for the Jenkins server
jenkins_swarm_domain_name: architect.internal.micahrl.com

jenkins_swarm_ssh_script_path: "{{ architect_ssh_script_path }}"

# architect-jenkins container settings
#
# The version of the architect-jenkins Docker image to use
# https://hub.docker.com/r/mrled/architect-jenkins/
jenkins_swarm_archjenks_tag: v0.0.8

# inflatable-wharf container settings
# Used to do DNS challenges for Let's Encrypt
#
# The version of the inflatable-wharf Docker image to use
# https://hub.docker.com/r/mrled/inflatable-wharf/
jenkins_swarm_inflwharf_tag: v0.0.6
# AWS creds
# These credentials are separate from the deployment credentials (above)
# because these are permanently saved to your EC2 instance
# and therefore should have restricted settings to update your zone
jenkins_swarm_inflwharf_aws_cfg:
    access: "{{ vault_inflwharf_aws_access_key }}"
    secret: "{{ vault_inflwharf_aws_secret_key }}"
    region: "{{ all_aws_cfg.region }}"
# The ID of the hosted zone
jenkins_swarm_inflwharf_aws_hosted_zone_id: Z2OOB3F1JEVLME
# The email address we send to Let's Encrypt via inflatable-wharf
jenkins_swarm_inflwharf_letsencrypt_email: psyops+architect@micahrl.com
# The Let's Encrypt server to use for generating the Architect TLS cert
# Use "staging" at first, to make sure everything works.
# This will prevent you from running into Let's Encrypt throttling,
# which can be quite severe (multiple days),
# but it will not generate certificates that are valid in browsers.
# Use "production" once everything works in staging;
# this is subject to harsh throttling, but will produce valid certs.
jenkins_swarm_inflwharf_lets_encrypt_server: production

# bsv container settings
# Used to back up to S3
#
# The version of bsv-docker to use
# https://hub.docker.com/r/mrled/bsv/
jenkins_swarm_bsv_tag: v0.0.2
# Backup schedule (cron format)
jenkins_swarm_bsv_backup_schedule: "0 2 * * *"
# Basename for the backup
jenkins_swarm_bsv_basename: archjenks
# GPG ID and public key of the backup encryption recipient
jenkins_swarm_bsv_recipient:
    id: 699A6782
    gpg_asc: |
        -----BEGIN PGP PUBLIC KEY BLOCK-----
        mQINBFZnWkwBEADIhNJ98iIja1drFiR9pyGFdeQ4Wdp0gi5PiW5DVwnLdj8iwJMw
        P9nktGYbnT/NyEt06LkhgXN1XY6ibAeNYf7ACvjxsetyincPRX32SUrBtkVX/V7v
        yT8Xnfj5bUoJASQZHEorvjb6TT+EcxmPO34R/heqa2hVcxmYLkXN1rHxMqTQ7FGU
        qDJIugjsWkNdRICpRlsw/1AZT9al05EXzc6jTBBugv10Z0wFt4ZroUmif2ymvAcu
        lhsLQEXVBKmqGPRwkn4CR2sW70Ee9YSah6mothY3FiWys3qvccdBQzzC0UisRgWI
        amx06btQbFB7OVjGdLeSKHzWepDzoK7QfwYVO8TsXXK0yq52h6xfqpMO7IeTBIUi
        HvDkIOVGgGpC668BhR4i602pVmZ8jePDMlck2Vv5L/DmjkXkDG7s7iVoblVCMqzc
        h7egc43JTGTCW0wf5dtsKB9XDdPJett5uHX2Dv0bPsr1y377/PNrdbRdj0avg4tT
        OTAAmf1mdBntmx5Gh19QSkfOhbJvy2AGdRq+G7Y/LIesO7zaG6w5wn86BzAHYvlk
        vMTMzKBmWq4waAwNCeCxa9iHaqkjArjiR9vWrP/tf9+tKlU/AHrv7FENu7+S2UEk
        Wkj84ZZ0GnXGb+IOB7M4sifUcSFUqjTW7WX2/4WLAlRwHDVYkyxOjYNYjQARAQAB
        tENNaWNhaCBSIExlZGJldHRlciAoQXV0b21hdGljIEJhY2t1cCBFbmNyeXB0aW9u
        KSA8bWljYWhAbWljYWhybC5jb20+iQI5BBMBCAAjBQJWZ1pMAhsDBwsJCAcDAgEG
        FQgCCQoLBBYCAwECHgECF4AACgkQeU9ndGmaZ4L8Dg/8CFMOtOygfiC5WQGzUjqb
        m6pHZ1iZWPBNuFP2uyPoKrzH51BQ6a0v80O2sOqBT5sdK0/VgcWytSxoL3+j86n+
        Rfnjyes2ueyT1Joeo4rbpWUQsSg7+6nV7rPa851bNU9AM5SyjR/JfxhW5u0UEw4m
        a6smwleEXH5Pcf1bFsHeWKLYmxel4xsmpmu/A+3QX2DF9YaHGTJqymgTmaTrbjxt
        lePLoVCASNnmRObBI01QfbymiFwSFw9TM7naxIiR6dS9OFK95WEkR8xN2Dd1imxY
        /EyTI3Wmo4YIo8QD7XLAOUP4C8P1IXknm2DVspcyVq0j3/rzi++hbeHpjDqQTRj3
        kParpu//mCiyIylLSHdGCjlx6oLqLxbfkr2oT9JxKjcoOx4Ly/K4g7V1BZyBN5Wz
        tsYDH1N9dSx1LGUlgqDuvXbUPMpq+HRUgaR2+YYnLi7npwWfvZK8gg5w4KuUTGL6
        DAw/fPXpWWZPIraMxrpOpkSDx25wA68glFGhgTWwl1jyJQUgZuJ1Cd0S1qZC5FDg
        xMaBQuyqATACqkzSZJyaPhjySnZwfiEs0DM8lWcP1ktXo+Y95Y5lG5aESvhJnIFp
        v7+61BhBAoLBm6ZDhsf5QsgOjclx5MqTD8sS0JqUGRDx3eCQslJYzOZqJPVy4yLq
        CvimtHKUvimKxtziU6On5n65Ag0EVmdaTAEQAOrvn4XISliloWMbk+tOUZCbJsnP
        dLYXhGr1yxgNyhKM9LNRCm8/g1rV03tURrw27fMwzW0/fv+KXz42F8jP8gChmNxV
        2eJMTp5apzYEL7+AxWSyEhLN232nknhE3pc3XL7sEHqqABaPCdeK7DdgLOsBv4U2
        hO43r3yTM8estpmJttebn8dOfz3KbFNMdbp9jZc5FvI0PfdnEo56ytAzscL2cElz
        +5FFPimJhVBq3ELJWSnb/I44vlTnrDaKpYqMgU780eDqjO2E134pg6g4nqH4yocN
        XOI6zgdhsQp0I8I2Ie4oj0RpRyLUtpa2WGYgrwhzc99MkbvsvzlZZMeTOlD4bjTP
        KBm4xNCVvwinVazB7fgi+H1+JhB/8ROzLvmie8m358rOm16BHbEWagKyMXyZUivw
        nXRgKL2Vn3ajvagowae7W3BGGzf8gQWUV6GtuYUt/WT1RWLxtQ3a0r07tjgukAx0
        8zRtOmSE7/JucnCixcf5BnEMgolXnmUvAPBWv6PXXn8uVtRn8ZRi/UV+cbXRCtIS
        wPK+G/wGkCYLhhMtZ370g7iZp3r7/g/wkK65P6ccgSqQ5szrUghKqyJZwXPQk0L8
        HB8hoEehoLz8MqvelHae/ue1M32v84COPb/410uUFVOUH/faG5LPYDhS35E2dz/3
        inszL+8GnAB+8I2VABEBAAGJAh8EGAEIAAkFAlZnWkwCGwwACgkQeU9ndGmaZ4LL
        lw/7B9GHi5a6mbORy2W40PAZp/Cu4yy6wqDKvvZKrOyGiFEd72wfcJ4nmEDG6uTx
        JzRXQKSvq0HvIZk8OOhhW+zKhSHHjlMhepRzkhVrA1RICyJyPGPfroCqDOMeHKEz
        Xr2IjL6HUXx96Tifw0/M4zpTy5Lbh5R9OgeP+A3ClFVdoKXBqNAlVvceZJV9iTbb
        dd/AEPBzVRpCKJNltFU0EpqGaTSwhFE81U/kBkDTj4sT5owC9U++P2DzqBcwXXEe
        usGQ4M4w1s4oUTuUdTwLKucR+zU4BoVKLIaQpDdIO2IZGuU/9Af+zIDaE5LyCR7t
        Uq1N8KJk5uYwjtqVdPS96tRVXT7VwyIlPVmRKL8ck5AEkHMJtH2bBtw71OQ92Ds4
        nyEDP8gj127d+oziSfa/0Ww1MPzN8do4nXYvl35KUzvC0zD08sdjLnetfqAMMQtP
        sbiwtxtRoC59kUOJwtyjDpQDjzmJ7TtCdzoUXm+43q0pVFvdtE4r8uGcilmxPpas
        h3yg78S09shuMrvc9QO23Zpv3LQyqwZsH6qyPCTXp4a52oXbpakqx/Zq0KZw3Ab2
        ygVLkx/7kiliE5r9Ab/avjyjl0RT39KkpNY5xmntZo/+Pm5m+KeEr25g+fVPm+T9
        cl8IMHeXkx5daztfAmzT2VEKPuGWKkpsCALDVBZI8l/4gE8=
        =7U8T
        -----END PGP PUBLIC KEY BLOCK-----
# S3 bucket to upload encrypted backup to
jenkins_swarm_bsv_s3_bucket: backups-autobackup-89d9f33ec6b04b22b358c1fca9844264c063ae6b
# bsv access and secret key
# These credentials are separate from the deployment credentials
# They should only allow uploading to the autobackup S3 bucket
jenkins_swarm_bsv_aws_cfg:
    access: "{{ vault_bsv_aws_access_key }}"
    secret: "{{ vault_bsv_aws_secret_key }}"
