- name: Decrypt local items
  hosts: localhost
  vars_files:
    - architect.cfg
    - architect.vault.cfg

  pre_tasks:
    - block:
      - name: Create working directory
        file:
          path: "{{ workdir }}"
          state: directory
          mode: 0700
      - import_tasks: tasks/process_ssh_client_key.yaml
      - import_tasks: tasks/process_ssh_host_key.yaml

- name: Deploy base server
  hosts: localhost
  vars_files:
    - architect.cfg
    - architect.vault.cfg

  roles:
    - role: cfn_architect_kms
    - role: kms_encrypt_secrets
    - role: cfn_architect_ci

  post_tasks:

    # The KMS stack is only used during CloudFormation::Init,
    # so we delete it here to prevent unnecessary charges
    # and to prevent non-root users from retrieving secrets after initial deployment
    - name: Delete the KMS stack
      cloudformation:
        aws_access_key: "{{ aws_access_key }}"
        aws_secret_key: "{{ aws_secret_key }}"
        region: "{{ aws_region }}"
        stack_name: "{{ architect_kms_stack_name }}"
        state: absent

    - name: Add new instance to host group
      add_host:
        name: "{{ architect_ip_address }}"
        groups: architect_host,swarm_manager
        ansible_ssh_user: "{{ architect_user }}"
        ansible_python_interpreter: "/usr/bin/python2.7"
        ansible_ssh_private_key_file: "{{ client_ssh_private_key_path }}"
        ansible_ssh_common_args: "-o UserKnownHostsFile={{ known_hosts_file }}"
        cloud_provider: ec2

    - block:
      - name: PWD
        shell: pwd
        register: pwd_result
      - set_fact:
          pwd: "{{ pwd_result.stdout }}"

    - set_fact:
        ssh_cmd: >-
          ssh -t
          -o UserKnownHostsFile={{ pwd }}/{{ workdir }}/known_hosts
          -i {{ pwd }}/{{ client_ssh_private_key_path }}
          {{ architect_user }}@{{ architect_ip_address }}

    - set_fact:
        ssh_script: |+
            #!/bin/sh
            set -eu
            {{ ssh_cmd }} "$@"
        success_msg: |
            Connecting to Architect, for debugging
            IP address              {{ architect_ip_address }}
            Host ECDSA fingerprint  {{ ssh_host_public_ecdsa_key_fingerprint }}
            SSH script              {{ ssh_script_path }}
            SSH script usage        {{ ssh_script_path }} sudo docker stack ls

    - name: Write SSH connection script
      copy:
        content: "{{ ssh_script }}"
        dest: "{{ ssh_script_path }}"
        mode: 0700

    - name: Success!
      debug:
        msg: "{{ success_msg.split('\n') }}"

- name: Configure the server
  hosts: architect_host
  become: true
  vars_files:
    - architect.cfg
    - architect.vault.cfg
  roles:
    - role: vpn_client
    - role: docker_install

- name: Initialize the Docker Swarm
  import_playbook: playbooks/docker_swarm.yaml
  # We must set the default value here,
  # because _naturally_ we cannot include vars_files in an import_playbook task
  when: skip_architect_initialize_swarm | default(false) | bool == false

- name: Deploy Jenkins service to Docker Swarm
  hosts: architect_host
  become: true
  vars_files:
    - architect.cfg
    - architect.vault.cfg
  roles:
    - role: docker_jenkins
